{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pandas\n","  Using cached pandas-1.3.5-cp37-cp37m-macosx_10_9_x86_64.whl (11.0 MB)\n","Collecting numpy\n","  Using cached numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n","Collecting pytz>=2017.3\n","  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n","Requirement already satisfied: python-dateutil>=2.7.3 in ./kavida-env/lib/python3.7/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in ./kavida-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n","Installing collected packages: numpy, pytz, pandas\n","Successfully installed numpy-1.21.6 pandas-1.3.5 pytz-2023.3\n","\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.2.1 is available.\n","You should consider upgrading via the '/Users/sparshjhariya/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install pandas numpy"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import pandas as pd \n","import numpy as np"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyarrow\n","  Downloading pyarrow-12.0.1-cp37-cp37m-macosx_10_14_x86_64.whl (24.7 MB)\n","\u001b[K     |████████████████████████████████| 24.7 MB 355 kB/s eta 0:00:01    |███████                         | 5.5 MB 982 kB/s eta 0:00:20     |███████████████▏                | 11.7 MB 409 kB/s eta 0:00:32     |████████████████                | 12.4 MB 971 kB/s eta 0:00:13\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in ./kavida-env/lib/python3.7/site-packages (from pyarrow) (1.21.6)\n","Installing collected packages: pyarrow\n","Successfully installed pyarrow-12.0.1\n","\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.2.1 is available.\n","You should consider upgrading via the '/Users/sparshjhariya/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install pyarrow"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import pyarrow"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:32:33.852529Z","iopub.status.busy":"2023-07-29T04:32:33.852161Z","iopub.status.idle":"2023-07-29T04:32:33.870505Z","shell.execute_reply":"2023-07-29T04:32:33.869548Z","shell.execute_reply.started":"2023-07-29T04:32:33.852499Z"},"trusted":true},"outputs":[],"source":["df = pd.read_parquet(\"query_result_2000.993493Z (1).parquet\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:26.405763Z","iopub.status.busy":"2023-07-29T04:18:26.405278Z","iopub.status.idle":"2023-07-29T04:18:26.429134Z","shell.execute_reply":"2023-07-29T04:18:26.428288Z","shell.execute_reply.started":"2023-07-29T04:18:26.405725Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>paragraph</th>\n","      <th>news_list</th>\n","      <th>event_timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Will the Covid-19 Grinch cancel a Santa rally ...</td>\n","      <td>OPINION: Stock markets typically trade higher ...</td>\n","      <td>[\"Supplier Market\"]</td>\n","      <td>2021-12-20T12:34:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SPDR S&amp;P XOP ETF In A Multi-Year Uptrend; Buy ...</td>\n","      <td>SPDR S&amp;P Oil &amp; Gas Exploration &amp; Production ET...</td>\n","      <td>[\"Financial Health\"]</td>\n","      <td>2021-12-20T12:31:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Britain reports 10,000 new Omicron cases, ‘maj...</td>\n","      <td>The total number of Omicron cases recorded acr...</td>\n","      <td>[\"Environmental\"]</td>\n","      <td>2021-12-20T12:31:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Risk aversion sentiment continues to percolate</td>\n","      <td>- Risk aversion sentiment on rapid spread of t...</td>\n","      <td>[\"Commodities\"]</td>\n","      <td>2021-12-20T12:30:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Omicron rush on boosters may make it harder to...</td>\n","      <td>Countries are saying three vaccine doses are n...</td>\n","      <td>[\"Commodities\"]</td>\n","      <td>2021-12-20T12:16:00Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  \\\n","0  Will the Covid-19 Grinch cancel a Santa rally ...   \n","1  SPDR S&P XOP ETF In A Multi-Year Uptrend; Buy ...   \n","2  Britain reports 10,000 new Omicron cases, ‘maj...   \n","3     Risk aversion sentiment continues to percolate   \n","4  Omicron rush on boosters may make it harder to...   \n","\n","                                           paragraph             news_list  \\\n","0  OPINION: Stock markets typically trade higher ...   [\"Supplier Market\"]   \n","1  SPDR S&P Oil & Gas Exploration & Production ET...  [\"Financial Health\"]   \n","2  The total number of Omicron cases recorded acr...     [\"Environmental\"]   \n","3  - Risk aversion sentiment on rapid spread of t...       [\"Commodities\"]   \n","4  Countries are saying three vaccine doses are n...       [\"Commodities\"]   \n","\n","        event_timestamp  \n","0  2021-12-20T12:34:00Z  \n","1  2021-12-20T12:31:00Z  \n","2  2021-12-20T12:31:00Z  \n","3  2021-12-20T12:30:00Z  \n","4  2021-12-20T12:16:00Z  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:28.638319Z","iopub.status.busy":"2023-07-29T04:18:28.637951Z","iopub.status.idle":"2023-07-29T04:18:28.665504Z","shell.execute_reply":"2023-07-29T04:18:28.664558Z","shell.execute_reply.started":"2023-07-29T04:18:28.638290Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>paragraph</th>\n","      <th>news_list</th>\n","      <th>event_timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>1970</td>\n","      <td>1944</td>\n","      <td>6</td>\n","      <td>1768</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Twitter @PDChina #omicron</td>\n","      <td>Welcome to Tuesday, where Omicron now looms ov...</td>\n","      <td>[\"Environmental\"]</td>\n","      <td>2021-12-16T20:16:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>545</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            title  \\\n","count                        2000   \n","unique                       1970   \n","top     Twitter @PDChina #omicron   \n","freq                            7   \n","\n","                                                paragraph          news_list  \\\n","count                                                2000               2000   \n","unique                                               1944                  6   \n","top     Welcome to Tuesday, where Omicron now looms ov...  [\"Environmental\"]   \n","freq                                                    5                545   \n","\n","             event_timestamp  \n","count                   2000  \n","unique                  1768  \n","top     2021-12-16T20:16:00Z  \n","freq                       4  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:31.333717Z","iopub.status.busy":"2023-07-29T04:18:31.333300Z","iopub.status.idle":"2023-07-29T04:18:31.351727Z","shell.execute_reply":"2023-07-29T04:18:31.350515Z","shell.execute_reply.started":"2023-07-29T04:18:31.333682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2000 entries, 0 to 1999\n","Data columns (total 4 columns):\n"," #   Column           Non-Null Count  Dtype \n","---  ------           --------------  ----- \n"," 0   title            2000 non-null   object\n"," 1   paragraph        2000 non-null   object\n"," 2   news_list        2000 non-null   object\n"," 3   event_timestamp  2000 non-null   object\n","dtypes: object(4)\n","memory usage: 62.6+ KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:33.685940Z","iopub.status.busy":"2023-07-29T04:18:33.684895Z","iopub.status.idle":"2023-07-29T04:18:33.693574Z","shell.execute_reply":"2023-07-29T04:18:33.692479Z","shell.execute_reply.started":"2023-07-29T04:18:33.685902Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['title', 'paragraph', 'news_list', 'event_timestamp'], dtype='object')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:33:35.193168Z","iopub.status.busy":"2023-07-29T04:33:35.192453Z","iopub.status.idle":"2023-07-29T04:33:35.200811Z","shell.execute_reply":"2023-07-29T04:33:35.199815Z","shell.execute_reply.started":"2023-07-29T04:33:35.193134Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['[\"Supplier Market\"]', '[\"Financial Health\"]', '[\"Environmental\"]',\n","       '[\"Commodities\"]', '[\"Compliance\"]', '[\"Delays\"]'], dtype=object)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df['news_list'].unique()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:38.111962Z","iopub.status.busy":"2023-07-29T04:18:38.111610Z","iopub.status.idle":"2023-07-29T04:18:38.118240Z","shell.execute_reply":"2023-07-29T04:18:38.117300Z","shell.execute_reply.started":"2023-07-29T04:18:38.111934Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2000"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(df['title'])"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:43.654245Z","iopub.status.busy":"2023-07-29T04:18:43.653252Z","iopub.status.idle":"2023-07-29T04:18:43.661052Z","shell.execute_reply":"2023-07-29T04:18:43.659930Z","shell.execute_reply.started":"2023-07-29T04:18:43.654194Z"},"trusted":true},"outputs":[{"data":{"text/plain":["4"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(df.columns)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch\n","  Downloading torch-1.13.1-cp37-none-macosx_10_9_x86_64.whl (135.3 MB)\n","\u001b[K     |████████████████████████████████| 135.3 MB 169 kB/s eta 0:00:01   |█▉                              | 7.7 MB 99 kB/s eta 0:21:21     |████▏                           | 17.8 MB 1.1 MB/s eta 0:01:51     |██████████████                  | 58.8 MB 1.0 MB/s eta 0:01:16     |██████████████████▋             | 78.7 MB 2.0 MB/s eta 0:00:29     |███████████████████████▋        | 100.0 MB 597 kB/s eta 0:01:00\n","\u001b[?25hCollecting typing-extensions\n","  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n","Installing collected packages: typing-extensions, torch\n","Successfully installed torch-1.13.1 typing-extensions-4.7.1\n","\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.2.1 is available.\n","You should consider upgrading via the '/Users/sparshjhariya/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install torch"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[K     |████████████████████████████████| 7.2 MB 627 kB/s eta 0:00:01\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp37-cp37m-macosx_10_11_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 956 kB/s eta 0:00:01\n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0.1-cp37-cp37m-macosx_10_9_x86_64.whl (189 kB)\n","\u001b[K     |████████████████████████████████| 189 kB 852 kB/s eta 0:00:01\n","\u001b[?25hCollecting regex!=2019.12.17\n","  Downloading regex-2023.6.3-cp37-cp37m-macosx_10_9_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 819 kB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./kavida-env/lib/python3.7/site-packages (from transformers) (23.1)\n","Collecting huggingface-hub<1.0,>=0.14.1\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[K     |████████████████████████████████| 268 kB 1.6 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./kavida-env/lib/python3.7/site-packages (from transformers) (1.21.6)\n","Collecting requests\n","  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n","Collecting safetensors>=0.3.1\n","  Downloading safetensors-0.3.1-cp37-cp37m-macosx_10_11_x86_64.whl (400 kB)\n","\u001b[K     |████████████████████████████████| 400 kB 1.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting tqdm>=4.27\n","  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 2.4 MB/s eta 0:00:01\n","\u001b[?25hCollecting filelock\n","  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n","Collecting importlib-metadata; python_version < \"3.8\"\n","  Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in ./kavida-env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Collecting fsspec\n","  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n","\u001b[K     |████████████████████████████████| 143 kB 1.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting idna<4,>=2.5\n","  Using cached idna-3.4-py3-none-any.whl (61 kB)\n","Collecting urllib3<3,>=1.21.1\n","  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 446 kB/s eta 0:00:01\n","\u001b[?25hCollecting charset-normalizer<4,>=2\n","  Using cached charset_normalizer-3.2.0-cp37-cp37m-macosx_10_9_x86_64.whl (122 kB)\n","Collecting certifi>=2017.4.17\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 1.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting zipp>=0.5\n","  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n","Installing collected packages: tokenizers, pyyaml, regex, idna, urllib3, charset-normalizer, certifi, requests, zipp, importlib-metadata, filelock, tqdm, fsspec, huggingface-hub, safetensors, transformers\n","Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 filelock-3.12.2 fsspec-2023.1.0 huggingface-hub-0.16.4 idna-3.4 importlib-metadata-6.7.0 pyyaml-6.0.1 regex-2023.6.3 requests-2.31.0 safetensors-0.3.1 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.30.2 urllib3-2.0.4 zipp-3.15.0\n","\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.2.1 is available.\n","You should consider upgrading via the '/Users/sparshjhariya/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:46.758731Z","iopub.status.busy":"2023-07-29T04:18:46.758279Z","iopub.status.idle":"2023-07-29T04:18:58.896092Z","shell.execute_reply":"2023-07-29T04:18:58.895116Z","shell.execute_reply.started":"2023-07-29T04:18:46.758696Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/sparshjhariya/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:18:58.898277Z","iopub.status.busy":"2023-07-29T04:18:58.897855Z","iopub.status.idle":"2023-07-29T04:18:58.906151Z","shell.execute_reply":"2023-07-29T04:18:58.905168Z","shell.execute_reply.started":"2023-07-29T04:18:58.898242Z"},"trusted":true},"outputs":[{"data":{"text/plain":["6"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["len(df['news_list'].unique())"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:13.206485Z","iopub.status.busy":"2023-07-29T04:34:13.205517Z","iopub.status.idle":"2023-07-29T04:34:13.452600Z","shell.execute_reply":"2023-07-29T04:34:13.451618Z","shell.execute_reply.started":"2023-07-29T04:34:13.206452Z"},"trusted":true},"outputs":[],"source":["for i in range(len(df['news_list'])):\n","    if df['news_list'][i] == '[\"Supplier Market\"]':\n","        df['news_list'][i] = 0\n","    elif df['news_list'][i] == '[\"Financial Health\"]':\n","        df['news_list'][i] = 1\n","    elif df['news_list'][i] == '[\"Environmental\"]':\n","        df['news_list'][i] = 2\n","    elif df['news_list'][i] == '[\"Commodities\"]':\n","        df['news_list'][i] = 3\n","    elif df['news_list'][i] == '[\"Compliance\"]':\n","        df['news_list'][i] = 4\n","    else:\n","        df['news_list'][i] = 5"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:16.822347Z","iopub.status.busy":"2023-07-29T04:34:16.821975Z","iopub.status.idle":"2023-07-29T04:34:16.833471Z","shell.execute_reply":"2023-07-29T04:34:16.832416Z","shell.execute_reply.started":"2023-07-29T04:34:16.822317Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>paragraph</th>\n","      <th>news_list</th>\n","      <th>event_timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Will the Covid-19 Grinch cancel a Santa rally ...</td>\n","      <td>OPINION: Stock markets typically trade higher ...</td>\n","      <td>0</td>\n","      <td>2021-12-20T12:34:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SPDR S&amp;P XOP ETF In A Multi-Year Uptrend; Buy ...</td>\n","      <td>SPDR S&amp;P Oil &amp; Gas Exploration &amp; Production ET...</td>\n","      <td>1</td>\n","      <td>2021-12-20T12:31:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Britain reports 10,000 new Omicron cases, ‘maj...</td>\n","      <td>The total number of Omicron cases recorded acr...</td>\n","      <td>2</td>\n","      <td>2021-12-20T12:31:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Risk aversion sentiment continues to percolate</td>\n","      <td>- Risk aversion sentiment on rapid spread of t...</td>\n","      <td>3</td>\n","      <td>2021-12-20T12:30:00Z</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Omicron rush on boosters may make it harder to...</td>\n","      <td>Countries are saying three vaccine doses are n...</td>\n","      <td>3</td>\n","      <td>2021-12-20T12:16:00Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  \\\n","0  Will the Covid-19 Grinch cancel a Santa rally ...   \n","1  SPDR S&P XOP ETF In A Multi-Year Uptrend; Buy ...   \n","2  Britain reports 10,000 new Omicron cases, ‘maj...   \n","3     Risk aversion sentiment continues to percolate   \n","4  Omicron rush on boosters may make it harder to...   \n","\n","                                           paragraph news_list  \\\n","0  OPINION: Stock markets typically trade higher ...         0   \n","1  SPDR S&P Oil & Gas Exploration & Production ET...         1   \n","2  The total number of Omicron cases recorded acr...         2   \n","3  - Risk aversion sentiment on rapid spread of t...         3   \n","4  Countries are saying three vaccine doses are n...         3   \n","\n","        event_timestamp  \n","0  2021-12-20T12:34:00Z  \n","1  2021-12-20T12:31:00Z  \n","2  2021-12-20T12:31:00Z  \n","3  2021-12-20T12:30:00Z  \n","4  2021-12-20T12:16:00Z  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:19.203617Z","iopub.status.busy":"2023-07-29T04:34:19.203241Z","iopub.status.idle":"2023-07-29T04:34:19.211542Z","shell.execute_reply":"2023-07-29T04:34:19.210653Z","shell.execute_reply.started":"2023-07-29T04:34:19.203568Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([0, 1, 2, 3, 4, 5], dtype=object)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df['news_list'].unique()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:23.887935Z","iopub.status.busy":"2023-07-29T04:34:23.887556Z","iopub.status.idle":"2023-07-29T04:34:23.894259Z","shell.execute_reply":"2023-07-29T04:34:23.892660Z","shell.execute_reply.started":"2023-07-29T04:34:23.887904Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","BATCH_SIZE = 16\n","NUM_CLASSES = len(df['news_list'].unique())\n","MAX_LENGTH = 128\n","LEARNING_RATE = 2e-5\n","EPOCHS = 3"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:27.325813Z","iopub.status.busy":"2023-07-29T04:34:27.325408Z","iopub.status.idle":"2023-07-29T04:34:28.823853Z","shell.execute_reply":"2023-07-29T04:34:28.822946Z","shell.execute_reply.started":"2023-07-29T04:34:27.325780Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 0cb47d18-9d73-468c-bc77-2a07bc48a2d4)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A"]},{"ename":"ConnectionError","evalue":"HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mtimeout\u001b[0m: The read operation timed out","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    834\u001b[0m                     \u001b[0;31m# Content-Length are caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_bytes_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0;31m# there is yet no clean way to get at it from this context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Read timed out.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/var/folders/jz/lbsl9gk92tq6gkzlftn5h_6h0000gn/T/ipykernel_5110/3705529610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bert-base-uncased'\u001b[0m  \u001b[0;31m# You can also try other models like 'bert-large-uncased'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m                     }\n\u001b[0;32m-> 2494\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                 \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mexpected_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Desktop/TECHY/Internship/Tasks/Kavida/kavida-env/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mReadTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRequestsSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out."]}],"source":["# Define the pre-trained model and tokenizer\n","model_name = 'bert-base-uncased'  # You can also try other models like 'bert-large-uncased'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=NUM_CLASSES)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:51.639417Z","iopub.status.busy":"2023-07-29T04:34:51.639058Z","iopub.status.idle":"2023-07-29T04:34:51.649856Z","shell.execute_reply":"2023-07-29T04:34:51.648820Z","shell.execute_reply.started":"2023-07-29T04:34:51.639388Z"},"trusted":true},"outputs":[],"source":["# Define a custom dataset class for the news data\n","class NewsDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        text = str(self.data.iloc[index]['paragraph'])\n","        label = int(self.data.iloc[index]['news_list'])\n","        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length,\n","                                  return_tensors='pt')\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),\n","            'attention_mask': encoding['attention_mask'].squeeze(),\n","            'labels': torch.tensor(label)\n","        }"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:34:56.134706Z","iopub.status.busy":"2023-07-29T04:34:56.133647Z","iopub.status.idle":"2023-07-29T04:34:56.139942Z","shell.execute_reply":"2023-07-29T04:34:56.138923Z","shell.execute_reply.started":"2023-07-29T04:34:56.134664Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/jz/lbsl9gk92tq6gkzlftn5h_6h0000gn/T/ipykernel_5110/1969212148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the dataset and data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNewsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"]}],"source":["# Create the dataset and data loader\n","dataset = NewsDataset(df, tokenizer, MAX_LENGTH)\n","train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:35:01.149115Z","iopub.status.busy":"2023-07-29T04:35:01.147724Z","iopub.status.idle":"2023-07-29T04:35:01.279883Z","shell.execute_reply":"2023-07-29T04:35:01.278799Z","shell.execute_reply.started":"2023-07-29T04:35:01.149075Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# Set the device (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:35:27.138823Z","iopub.status.busy":"2023-07-29T04:35:27.137688Z","iopub.status.idle":"2023-07-29T04:35:27.149061Z","shell.execute_reply":"2023-07-29T04:35:27.147968Z","shell.execute_reply.started":"2023-07-29T04:35:27.138779Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Define the optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","loss_fn = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:35:30.247742Z","iopub.status.busy":"2023-07-29T04:35:30.246802Z","iopub.status.idle":"2023-07-29T04:35:30.258259Z","shell.execute_reply":"2023-07-29T04:35:30.257195Z","shell.execute_reply.started":"2023-07-29T04:35:30.247699Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Training loop\n","model.train()"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:35:32.884024Z","iopub.status.busy":"2023-07-29T04:35:32.883672Z","iopub.status.idle":"2023-07-29T04:36:58.027748Z","shell.execute_reply":"2023-07-29T04:36:58.026772Z","shell.execute_reply.started":"2023-07-29T04:35:32.883996Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Loss: 1.6016822128295898\n","Epoch 2/3, Loss: 1.3344850406646729\n","Epoch 3/3, Loss: 1.0484017910957337\n"]}],"source":["for epoch in range(EPOCHS):\n","    total_loss = 0\n","    for batch in train_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Forward pass\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_loss}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:11:12.722160Z","iopub.status.idle":"2023-07-29T04:11:12.722729Z","shell.execute_reply":"2023-07-29T04:11:12.722474Z","shell.execute_reply.started":"2023-07-29T04:11:12.722445Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","\n","# Load the data into a DataFrame (Replace 'your_data.csv' with the path to your data file)\n","# df = pd.read_csv('your_data.csv')\n","\n","# Define the pre-trained model and tokenizer\n","model_name = 'bert-base-uncased'  # You can also try other models like 'bert-large-uncased'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=NUM_CLASSES)\n","\n","# Define a custom dataset class for the news data\n","class NewsDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        text = str(self.data.iloc[index]['text'])\n","        label = int(self.data.iloc[index]['label'])\n","        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length,\n","                                  return_tensors='pt')\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),\n","            'attention_mask': encoding['attention_mask'].squeeze(),\n","            'labels': torch.tensor(label)\n","        }\n","\n","# Hyperparameters\n","BATCH_SIZE = 16\n","NUM_CLASSES = len(df['label'].unique())\n","MAX_LENGTH = 128\n","LEARNING_RATE = 2e-5\n","EPOCHS = 3\n","\n","# Create the dataset and data loader\n","dataset = NewsDataset(df, tokenizer, MAX_LENGTH)\n","train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Set the device (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define the optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# Training loop\n","model.train()\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    for batch in train_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Forward pass\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_loss}')\n","\n","# Save the trained model\n","model.save_pretrained('news_classification_model')\n","tokenizer.save_pretrained('news_classification_model')\n"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:37:31.535462Z","iopub.status.busy":"2023-07-29T04:37:31.535105Z","iopub.status.idle":"2023-07-29T04:37:31.543319Z","shell.execute_reply":"2023-07-29T04:37:31.542180Z","shell.execute_reply.started":"2023-07-29T04:37:31.535432Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'OPINION: Stock markets typically trade higher at this time with a ‘Santa rally’ as investors are typically in an ebullient mood, but Omicron could be the Grinch.'"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["def preprocess_text(text, tokenizer, max_length):\n","    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n","    return inputs\n","\n","# Example input text\n","input_text = \"This is a sample news text.\"\n","\n","# Preprocess the text\n","inputs = preprocess_text(input_text, tokenizer, max_length=128)\n"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:39:35.555673Z","iopub.status.busy":"2023-07-29T04:39:35.555269Z","iopub.status.idle":"2023-07-29T04:39:36.197519Z","shell.execute_reply":"2023-07-29T04:39:36.196551Z","shell.execute_reply.started":"2023-07-29T04:39:35.555639Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('news_classification_model/tokenizer_config.json',\n"," 'news_classification_model/special_tokens_map.json',\n"," 'news_classification_model/vocab.txt',\n"," 'news_classification_model/added_tokens.json')"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# Save the trained model\n","model.save_pretrained('news_classification_model')\n","tokenizer.save_pretrained('news_classification_model')"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:41:36.913422Z","iopub.status.busy":"2023-07-29T04:41:36.912496Z","iopub.status.idle":"2023-07-29T04:41:38.234138Z","shell.execute_reply":"2023-07-29T04:41:38.233153Z","shell.execute_reply.started":"2023-07-29T04:41:36.913376Z"},"trusted":true},"outputs":[],"source":["# Testing the model\n","from transformers import BertTokenizer, BertForSequenceClassification\n","\n","model_path = '/kaggle/working/news_classification_model'  # Replace with the path to the directory where the model is saved\n","tokenizer = BertTokenizer.from_pretrained(model_path)\n","model = BertForSequenceClassification.from_pretrained(model_path)\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:43:04.002194Z","iopub.status.busy":"2023-07-29T04:43:04.001813Z","iopub.status.idle":"2023-07-29T04:43:04.008658Z","shell.execute_reply":"2023-07-29T04:43:04.007536Z","shell.execute_reply.started":"2023-07-29T04:43:04.002164Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'OPINION: Stock markets typically trade higher at this time with a ‘Santa rally’ as investors are typically in an ebullient mood, but Omicron could be the Grinch.'"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["df['paragraph'][0]"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:46:01.221675Z","iopub.status.busy":"2023-07-29T04:46:01.220611Z","iopub.status.idle":"2023-07-29T04:46:01.229556Z","shell.execute_reply":"2023-07-29T04:46:01.228374Z","shell.execute_reply.started":"2023-07-29T04:46:01.221626Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["df['news_list'][0]"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:46:31.377134Z","iopub.status.busy":"2023-07-29T04:46:31.376421Z","iopub.status.idle":"2023-07-29T04:46:31.383432Z","shell.execute_reply":"2023-07-29T04:46:31.382459Z","shell.execute_reply.started":"2023-07-29T04:46:31.377101Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'SPDR S&P Oil & Gas Exploration & Production ETF XOP has recently sold off the highs on the back of the new Covid Omicron variant. Check out my trading strategy.'"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["df['paragraph'][1000]"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:46:42.348361Z","iopub.status.busy":"2023-07-29T04:46:42.347997Z","iopub.status.idle":"2023-07-29T04:46:42.355819Z","shell.execute_reply":"2023-07-29T04:46:42.354649Z","shell.execute_reply.started":"2023-07-29T04:46:42.348331Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["df['news_list'][1000]"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:46:50.157593Z","iopub.status.busy":"2023-07-29T04:46:50.157175Z","iopub.status.idle":"2023-07-29T04:46:50.168400Z","shell.execute_reply":"2023-07-29T04:46:50.167384Z","shell.execute_reply.started":"2023-07-29T04:46:50.157546Z"},"trusted":true},"outputs":[],"source":["def preprocess_text(text, tokenizer, max_length):\n","    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n","    return inputs\n","\n","# Example input text\n","input_text = df['paragraph'][1000]\n","\n","# Preprocess the text\n","inputs = preprocess_text(input_text, tokenizer, max_length=128)\n"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T04:46:52.492164Z","iopub.status.busy":"2023-07-29T04:46:52.491443Z","iopub.status.idle":"2023-07-29T04:46:52.815191Z","shell.execute_reply":"2023-07-29T04:46:52.813985Z","shell.execute_reply.started":"2023-07-29T04:46:52.492123Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Label: 2\n","Label Probabilities: [0.005755815654993057, 0.04628727212548256, 0.555588960647583, 0.12563663721084595, 0.008880961686372757, 0.2578503489494324]\n"]}],"source":["import torch\n","\n","# Set the device (GPU if available, else CPU)\n","device = torch.device('cpu')\n","\n","# Move the inputs to the appropriate device\n","inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Make predictions\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get the predicted label and probabilities\n","predicted_label = torch.argmax(outputs.logits, dim=1).item()\n","label_probabilities = torch.softmax(outputs.logits, dim=1).squeeze().tolist()\n","\n","print(f\"Predicted Label: {predicted_label}\")\n","print(f\"Label Probabilities: {label_probabilities}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
